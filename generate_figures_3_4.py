# -*- coding: utf-8 -*-
"""
Generates Figures 3 and 4 for the IRCU Dynamics manuscript using simulation output.

This script loads pre-computed simulation data (time series and sensitivity summaries)
from CSV files generated by a separate ODE simulation script 
(e.g., Ode_Simulations_Figures3_Figures4.py). 
It then uses matplotlib to create professionally styled plots:
- Figure 3: Time series plots for scenarios A1, B1, B2, B3 with annotations.
- Figure 4: Sensitivity analysis plots for parameters gamma and epsilon.

Expected Input CSVs (in specified subdirectories):
- ./simulation_results/csv_data/*.csv (e.g., A1_base_autonomous_data_full_export.csv)
- ./patient_data.csv (For calculating real cohort proportions)

Output Figures:
- Saved as PNG files in ./simulation_results/plots/ (or a custom output dir).
"""
#%%
# Section 1: Imports and Configuration
# -------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import os
import sys # To potentially exit if files are missing
from typing import Union, Dict, List, Tuple, Optional

print("--- Script Start ---")

# --- Configuration ---
# Set global matplotlib styles for professional look
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 13
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 11
plt.rcParams['ytick.labelsize'] = 11
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['savefig.format'] = 'png' # Output format
plt.rcParams['figure.facecolor'] = 'white' # White background
# Ensure axes are boxed
plt.rcParams['axes.edgecolor'] = 'black'
plt.rcParams['axes.linewidth'] = 1.0
# Explicitly ensure all spines are visible by default (can be overridden per axis)
plt.rcParams['axes.spines.left'] = True
plt.rcParams['axes.spines.right'] = True
plt.rcParams['axes.spines.bottom'] = True
plt.rcParams['axes.spines.top'] = True
plt.rcParams['lines.linewidth'] = 2.0 # Default line width

# Define Input/Output Directories (Relative to script location)
BASE_OUTPUT_DIR = "simulation_results" # Matches output of simulation script
CSV_DATA_DIR = os.path.join(BASE_OUTPUT_DIR, "csv_data") # <--- DEFINE el directorio de datos CSV
PLOT_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, "plots") # <--- DEFINE el directorio de plots
REAL_DATA_FILE = "patient_data.csv"

# --- Create output directories if they don't exist ---
# Crea el directorio base si es necesario
os.makedirs(BASE_OUTPUT_DIR, exist_ok=True) 
# Crea el directorio de plots si no existe
os.makedirs(PLOT_OUTPUT_DIR, exist_ok=True)
# ***** NUEVA LÍNEA: Crea el directorio de datos CSV si no existe *****
os.makedirs(CSV_DATA_DIR, exist_ok=True) 
# ******************************************************************
print(f"CSV data directory ensured: '{CSV_DATA_DIR}'") # Mensaje actualizado/añadido
print(f"Plot output directory ensured: '{PLOT_OUTPUT_DIR}'")

# Define filenames for simulation results
# Ensure these match the exact filenames generated by the ODE script
# Using '_data_full_export.csv' for time series and '_summary_full.csv' for sensitivity
SIM_FILENAMES = {
    "A1": "A1_base_autonomous_data_full_export.csv",
    "B1": "B1_variable_A_data_full_export.csv",
    "B2": "B2_variable_theta_data_full_export.csv",
    "B3": "B3_variable_A_theta_data_full_export.csv",
}
SENS_FILENAMES = {
    "C3": "C3_sensitivity_gamma_outcomes_summary_full.csv", # Assuming name from ODE script
    "C4": "C4_sensitivity_epsilon_outcomes_summary_full.csv",# Assuming name from ODE script
}
# Base parameter values needed for sensitivity plots (should match values used in ODE script)
# These ideally should be read from the simulation script's output or stored consistently.
# Using placeholders - replace with actual values if known, or extract from summary files.
PARAM_BASE_VALUES = {
    'gamma': 0.05, # Replace with actual base value
    'epsilon': 0.01 # Replace with actual base value
}


# --- Helper Function ---
def check_files_exist(directory, filenames_dict):
    """Checks if all files in the dictionary exist in the directory."""
    all_exist = True
    for key, fname in filenames_dict.items():
        fpath = os.path.join(directory, fname)
        if not os.path.exists(fpath):
            # Cambia el ERROR a un WARNING si ahora creamos la carpeta
            print(f"WARNING: Required input file not found: '{fpath}'") 
            print(f"         (The directory '{directory}' exists, but the file is missing.)")
            all_exist = False
    return all_exist

# Check required directories and files before proceeding
if not os.path.isdir(CSV_DATA_DIR):
     print(f"ERROR: CSV data directory not found: '{CSV_DATA_DIR}'")
    # sys.exit(1)
if not check_files_exist(CSV_DATA_DIR, SIM_FILENAMES):
     print("Exiting due to missing simulation time series CSV files.")
    # sys.exit(1)
if not check_files_exist(CSV_DATA_DIR, SENS_FILENAMES):
     print("Exiting due to missing sensitivity summary CSV files.")
     #sys.exit(1)
if not os.path.exists(REAL_DATA_FILE):
     print(f"ERROR: Real patient data file not found: '{REAL_DATA_FILE}'")
if not check_files_exist(CSV_DATA_DIR, SIM_FILENAMES):
     print("WARNING: One or more simulation time series CSV files are missing.")
     # Ya no salimos: sys.exit(1) 
if not check_files_exist(CSV_DATA_DIR, SENS_FILENAMES):
     print("WARNING: One or more sensitivity summary CSV files are missing.")     
     # Optionally continue without real data comparison
     # sys.exit(1)


# Section 2: Data Loading Classes
# --------------------------------
class DataLoader:
    """
    Loads CSV simulation output files and provides access to required data.
    Handles both time series and sensitivity summary files.
    """
    def __init__(self, filepath: str):
        """Loads CSV file into self.df."""
        self.filepath = filepath
        try:
            # Assume comma separator based on previous script update
            self.df = pd.read_csv(filepath, sep=',')
            print(f"Successfully loaded: '{os.path.basename(filepath)}'")
            # Basic check for expected time series columns
            if 't' not in self.df.columns and 'parameter_value' not in self.df.columns:
                 print(f"Warning: Neither 't' nor 'parameter_value' found in {filepath}. Assuming time series.")
        except FileNotFoundError:
            print(f"ERROR: File not found during DataLoader init: '{filepath}'")
            self.df = pd.DataFrame() # Empty DataFrame
        except Exception as e:
            print(f"ERROR loading CSV '{filepath}': {e}")
            self.df = pd.DataFrame() # Empty DataFrame

    def get_time_series(self, cols: List[str]) -> Tuple[Union[np.ndarray, None], Dict[str, np.ndarray]]:
        """Returns time array and a dictionary of requested time series columns."""
        if self.df.empty or 't' not in self.df.columns:
            print(f"Warning: Cannot get time series from '{os.path.basename(self.filepath)}' (empty or no 't' column).")
            return None, {col: np.array([]) for col in cols}
        
        required_cols = ['t'] + cols
        missing_cols = [col for col in required_cols if col not in self.df.columns]
        if missing_cols:
             print(f"Warning: Missing columns in '{os.path.basename(self.filepath)}': {missing_cols}")
             # Return empty arrays for missing cols, but still return time and existing cols
             data_dict = {}
             for col in cols:
                  if col in self.df.columns:
                       data_dict[col] = self.df[col].values
                  else:
                       data_dict[col] = np.array([])
             return self.df['t'].values, data_dict

        t_array = self.df['t'].values
        series_dict = {col: self.df[col].values for col in cols}
        return t_array, series_dict

    def get_final_values(self, cols: list[str]) -> dict[str, float]:
        """Returns a dictionary of the last row's values for specified columns."""
        if self.df.empty or len(self.df) == 0:
            print(f"Warning: Cannot get final values from '{os.path.basename(self.filepath)}' (empty DataFrame).")
            return {col: np.nan for col in cols}

        final_vals = {}
        for col in cols:
            if col in self.df.columns:
                # Use iloc[-1] for the last row, handle potential NaN
                val = self.df[col].iloc[-1]
                final_vals[col] = float(val) if pd.notna(val) else np.nan
            else:
                print(f"Warning: Column '{col}' not found for final value extraction in '{os.path.basename(self.filepath)}'.")
                final_vals[col] = np.nan
        return final_vals

    def get_sensitivity_data(self, value_cols: List[str]) -> Tuple[Optional[np.ndarray], Dict[str, np.ndarray]]:
        """Returns parameter values array and a dictionary of outcome arrays."""
        param_col = 'parameter_value'
        if self.df.empty or param_col not in self.df.columns:
            print(f"Warning: Cannot get sensitivity data from '{os.path.basename(self.filepath)}' (empty or no '{param_col}' column).")
            return None, {col: np.array([]) for col in value_cols}

        missing_cols = [col for col in value_cols if col not in self.df.columns]
        if missing_cols:
            print(f"Warning: Missing outcome columns in sensitivity file '{os.path.basename(self.filepath)}': {missing_cols}")

        param_values = self.df[param_col].values
        results_dict = {}
        for col in value_cols:
             if col in self.df.columns:
                  results_dict[col] = self.df[col].values
             else:
                  results_dict[col] = np.full_like(param_values, np.nan) # Fill missing with NaN

        return param_values, results_dict


# Section 3: Simulation Plotter Classes
# -------------------------------------
class SimulationPlotter:
    """
    Plots time series for X, Y, Z, W, R vs t, with annotations.
    """
    def __init__(self, t: np.ndarray, series: dict[str, np.ndarray], title: str, filename_base: str):
        """
        Initializes the plotter with time, series data, title, and base filename.
        Args:
            t (np.ndarray): Time points array.
            series (dict[str, np.ndarray]): Dictionary containing time series data for 'X', 'Y', 'Z', 'W', 'R'.
            title (str): Title for the plot.
            filename_base (str): Base name for saving the output figure file.
        """
        self.t = t
        self.series = series
        self.title = title
        self.filename_base = filename_base
        self.fig = None
        self.ax = None
        # Check if data is valid
        if self.t is None or not all(k in self.series for k in ['X', 'Y', 'Z', 'W', 'R']) or len(self.t) == 0:
             print(f"ERROR: Insufficient data provided for SimulationPlotter '{title}'. Plotting aborted.")
             self.valid = False
        else:
             self.valid = True
             # Pre-calculate final values needed for annotations
             self.final_vals = {k: v[-1] if len(v) > 0 else np.nan for k, v in self.series.items()}
             self.t_final = self.t[-1] if len(self.t) > 0 else np.nan

    def plot_main(self):
        """Creates and saves the main time series plot."""
        if not self.valid: return

        self.fig, self.ax = plt.subplots(figsize=(10, 6)) # Slightly smaller than script default

        colors = plt.cm.tab10 # Use a standard colormap

        # Plot X and Y as solid lines
        self.ax.plot(self.t, self.series['X'], label='No NIV (X)', color=colors(0), linestyle='-')
        self.ax.plot(self.t, self.series['Y'], label='NIV (Y)', color=colors(1), linestyle='-')

        # Plot Z, W, R as dashed or dotted
        self.ax.plot(self.t, self.series['Z'], label='Cumulative ICU (Z)', color=colors(2), linestyle='--')
        self.ax.plot(self.t, self.series['W'], label='Cumulative Exitus (W)', color=colors(3), linestyle=':')
        self.ax.plot(self.t, self.series['R'], label='Cumulative Recovered (R)', color=colors(4), linestyle='-.')

        # --- Add Annotations for Equilibrium/Stable Values ---
        # Find a suitable time point for annotation (e.g., 95% of t_final)
        t_annot = self.t_final * 0.95
        x_annot_val = np.interp(t_annot, self.t, self.series['X']) # Interpolate for smoother position
        y_annot_val = np.interp(t_annot, self.t, self.series['Y'])

        # Annotate X stable value
        self.ax.annotate(f'Stable X ≈ {self.final_vals["X"]:.1f}',
                         xy=(self.t_final, self.final_vals["X"]), # Point to the end value
                         xytext=(-50, 20), textcoords='offset points', # Offset text
                         ha='right', va='bottom', fontsize=9,
                         bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.7, ec='gray'),
                         arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2", color='gray'))

        # Annotate Y stable value
        self.ax.annotate(f'Stable Y ≈ {self.final_vals["Y"]:.1f}',
                         xy=(self.t_final, self.final_vals["Y"]), # Point to the end value
                         xytext=(-50, -25), textcoords='offset points', # Offset text below
                         ha='right', va='top', fontsize=9,
                         bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.7, ec='gray'),
                         arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=-.2", color='gray'))

        # (Optional) Indicate equilibrium point visually - subjective
        # Let's add a subtle vertical line around day 60 for A1 as an example point
        if "A1" in self.filename_base: # Only for A1 example
             t_equilibrium_approx = 60
             if self.t_final > t_equilibrium_approx:
                  self.ax.axvline(t_equilibrium_approx, color='grey', linestyle='--', linewidth=0.8, alpha=0.7)
                  self.ax.text(t_equilibrium_approx + 2, self.ax.get_ylim()[1]*0.95, 'Approx. Equilibrium',
                               rotation=90, va='top', ha='left', fontsize=8, color='grey', alpha=0.8)

        # --- Styling ---
        self.ax.set_xlabel("Time (days)")
        self.ax.set_ylabel("Number of Patients")
        self.ax.set_title(self.title)
        self.ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), frameon=True)
        self.ax.grid(True, which='major', linestyle='-', linewidth=0.5, alpha=0.6)
        self.ax.minorticks_on()
        self.ax.grid(True, which='minor', linestyle=':', linewidth=0.3, alpha=0.4)
        self.ax.set_ylim(bottom=0)
        self.ax.set_xlim(left=0, right=self.t_final*1.02) # Slightly extend x-axis

        # Ensure axes are boxed (redundant with rcParams but safe)
        for spine in self.ax.spines.values():
            spine.set_visible(True)
            spine.set_edgecolor('black')
            spine.set_linewidth(1.0)

        plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust right margin for legend

    def add_text_box(self, text_content: str, location: str = 'bottom_right'):
        """Adds a formatted text box to the plot."""
        if not self.valid or self.ax is None: return

        props = dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.85, edgecolor='black')
        if location == 'bottom_right':
             self.ax.text(0.98, 0.02, text_content, transform=self.ax.transAxes, fontsize=9,
                         verticalalignment='bottom', horizontalalignment='right', bbox=props)
        elif location == 'top_left':
             self.ax.text(0.02, 0.98, text_content, transform=self.ax.transAxes, fontsize=9,
                         verticalalignment='top', horizontalalignment='left', bbox=props)
        # Add other locations if needed

    def add_peak_annotation(self, series_key: str, label_prefix: str):
        """Adds an annotation for the peak value of a given series."""
        if not self.valid or self.ax is None or series_key not in self.series: return

        series_data = self.series[series_key]
        if len(series_data) == 0: return

        peak_value = np.nanmax(series_data)
        peak_idx = np.nanargmax(series_data)
        peak_time = self.t[peak_idx]

        # Only annotate if peak is significantly different from start/end?
        # Simple annotation for now:
        self.ax.annotate(f'{label_prefix} ≈ {peak_value:.1f}',
                         xy=(peak_time, peak_value),
                         xytext=(0, 30), textcoords='offset points', # Offset text above peak
                         ha='center', va='bottom', fontsize=9,
                         bbox=dict(boxstyle="round,pad=0.3", fc="wheat", alpha=0.8, ec='gray'),
                         arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0", color='black', shrinkB=5))


    def save_plot(self):
         """Saves the generated plot."""
         if not self.valid or self.fig is None:
              print(f"Skipping save for '{self.filename_base}' (invalid state).")
              return
         output_path = os.path.join(PLOT_OUTPUT_DIR, f"{self.filename_base}.png")
         try:
              self.fig.savefig(output_path, bbox_inches='tight')
              print(f"Plot saved: '{output_path}'")
         except Exception as e:
              print(f"ERROR saving plot '{output_path}': {e}")
         plt.close(self.fig) # Close figure to free memory


    # Optional: Separate plot for cumulative rates if needed (often combined or summarized)
    def plot_cumulative_rates(self):
        """Plots cumulative outcomes as percentage of cumulative admissions."""
        if not self.valid: return
        req_cols = ['Z_perc_vs_Cum_Admissions', 'W_perc_vs_Cum_Admissions', 'R_perc_vs_Cum_Admissions']
        if not all(c in self.series for c in req_cols):
             print(f"Skipping cumulative rates plot for {self.filename_base}: Missing data columns.")
             return

        fig_rate, ax_rate = plt.subplots(figsize=(8, 5)) # Smaller figure

        z_rate = self.series['Z_perc_vs_Cum_Admissions']
        w_rate = self.series['W_perc_vs_Cum_Admissions']
        r_rate = self.series['R_perc_vs_Cum_Admissions']

        ax_rate.plot(self.t, z_rate, label='% Admissions -> ICU (Z)', color=plt.cm.tab10(2), linestyle='--')
        ax_rate.plot(self.t, w_rate, label='% Admissions -> Exitus (W)', color=plt.cm.tab10(3), linestyle=':')
        ax_rate.plot(self.t, r_rate, label='% Admissions -> Recovered (R)', color=plt.cm.tab10(4), linestyle='-.')

        # Annotate final values
        ax_rate.text(self.t_final * 0.98, z_rate[-1], f'{z_rate[-1]:.1f}%', ha='right', va='bottom', fontsize=9, color=plt.cm.tab10(2))
        ax_rate.text(self.t_final * 0.98, w_rate[-1], f'{w_rate[-1]:.1f}%', ha='right', va='bottom', fontsize=9, color=plt.cm.tab10(3))
        ax_rate.text(self.t_final * 0.98, r_rate[-1], f'{r_rate[-1]:.1f}%', ha='right', va='bottom', fontsize=9, color=plt.cm.tab10(4))

        ax_rate.set_xlabel("Time (days)")
        ax_rate.set_ylabel("Cumulative Outcome Rate (%)")
        ax_rate.set_title(f"{self.title} - Outcome Rates vs Admissions")
        ax_rate.legend(loc='center right', fontsize=9)
        ax_rate.grid(True, linestyle=':')
        ax_rate.set_ylim(bottom=0, top=max(100, ax_rate.get_ylim()[1])) # Ensure y-axis goes to at least 100%
        ax_rate.set_xlim(left=0)

        for spine in ax_rate.spines.values(): spine.set_visible(True) # Ensure box

        plt.tight_layout()
        output_path = os.path.join(PLOT_OUTPUT_DIR, f"{self.filename_base}_cum_rates.png")
        try:
            fig_rate.savefig(output_path)
            print(f"Plot saved: '{output_path}'")
        except Exception as e:
            print(f"ERROR saving cumulative rates plot '{output_path}': {e}")
        plt.close(fig_rate)


# Section 4: Metrics Calculator Class
# -----------------------------------
class MetricsCalculator:
    """
    Computes metrics from simulation DataFrames (time series or real cohort).
    """
    def __init__(self, df: pd.DataFrame):
        """Initializes with a DataFrame."""
        if not isinstance(df, pd.DataFrame) or df.empty:
             print("Warning: MetricsCalculator initialized with empty or invalid DataFrame.")
             self.df = pd.DataFrame()
        else:
             self.df = df

    def compute_active_niv_final(self) -> tuple[float, float]:
        """Computes total active patients (X+Y) and % requiring NIV from the last row."""
        if self.df.empty or not all(c in self.df.columns for c in ['X', 'Y']) or len(self.df) == 0:
            return np.nan, np.nan

        final_row = self.df.iloc[-1]
        x_f, y_f = final_row['X'], final_row['Y']
        active = x_f + y_f
        # Use round for integer-like display, but keep float for percentage
        active_val = round(active) if pd.notna(active) else np.nan

        if active > 1e-9 and pd.notna(y_f): # Avoid division by zero or NaN
             perc_niv = (y_f / active) * 100
        else:
             perc_niv = 0.0 if active == 0 else np.nan # Handle zero active or NaN Y

        return active_val, perc_niv

    def compute_outcome_proportions_final(self) -> dict[str, float]:
        """Computes Z%, W%, R% from the final values of Z, W, R."""
        if self.df.empty or not all(c in self.df.columns for c in ['Z', 'W', 'R']) or len(self.df) == 0:
             return {'Z%': np.nan, 'W%': np.nan, 'R%': np.nan}

        final_row = self.df.iloc[-1]
        z_f, w_f, r_f = final_row['Z'], final_row['W'], final_row['R']

        total_outcomes = z_f + w_f + r_f

        if total_outcomes > 1e-9 and all(pd.notna([z_f, w_f, r_f])):
            z_pct = (z_f / total_outcomes) * 100
            w_pct = (w_f / total_outcomes) * 100
            r_pct = (r_f / total_outcomes) * 100
            return {'Z%': z_pct, 'W%': w_pct, 'R%': r_pct}
        else:
            print(f"Warning: Cannot compute final proportions (Total Outcomes={total_outcomes:.2f} or NaNs present).")
            return {'Z%': np.nan, 'W%': np.nan, 'R%': np.nan}

    def compute_real_cohort_proportions_for_niv(self) -> Optional[Dict[str, float]]:
        """
        Calculates observed outcome proportions FOR PATIENTS WHO USED NIV (SRNI=1),
        matching the logic used in parameter estimation. Assumes standard column names
        like 'SRNI', 'UCI', 'EXITUS' exist in the initialized DataFrame.
        """
        if self.df.empty or not all(c in self.df.columns for c in ['SRNI', 'UCI', 'EXITUS']):
             print("Warning: Cannot compute real cohort proportions for NIV. Missing columns in input DataFrame.")
             return None

        df_niv = self.df[self.df['SRNI'] == 1].copy()
        n_niv = len(df_niv)

        if n_niv == 0:
            print("Warning: No patients with SRNI=1 found in real cohort data.")
            return {'frac_icu%': 0.0, 'frac_exitus%': 0.0, 'frac_rec%': 0.0}

        n_icu_from_y = df_niv['UCI'].sum() # Assuming UCI=1 means transferred from NIV path
        # Exitus DIRECT from NIV path (EXITUS=1 AND UCI=0 among NIV users)
        n_exitus_from_y_no_uci = df_niv[(df_niv['EXITUS'] == 1) & (df_niv['UCI'] == 0)].shape[0]
        # Recovery from NIV path (neither UCI nor direct Exitus)
        n_recovered_from_y = n_niv - n_icu_from_y - n_exitus_from_y_no_uci

        # Calculate fractions (and convert to percentage)
        frac_icu = (n_icu_from_y / n_niv) * 100
        frac_exitus = (n_exitus_from_y_no_uci / n_niv) * 100
        frac_rec = (n_recovered_from_y / n_niv) * 100

        print(f"Real Cohort NIV Outcomes (n={n_niv}): "
              f"ICU={frac_icu:.1f}%, Exitus(Direct)={frac_exitus:.1f}%, Recovered={frac_rec:.1f}%")
        return {'frac_icu%': frac_icu, 'frac_exitus%': frac_exitus, 'frac_rec%': frac_rec}

    def get_max_value(self, col: str) -> float:
        """ Gets the maximum value of a specified column. """
        if self.df.empty or col not in self.df.columns:
            return np.nan
        return self.df[col].max()


# Section 7: Sensitivity Analysis Classes (Revised)
# ---------------------------------------
class SensitivityPlotter:
    """
    Generates sensitivity plots using data loaded from summary CSV files.
    """
    def __init__(self, results_df: pd.DataFrame, param_name: str, param_symbol: str, base_value: Optional[float], filename_base: str):
        """
        Initializes with sensitivity results DataFrame, parameter name/symbol, base value, and filename base.
        """
        self.df = results_df
        self.param_name = param_name        # e.g., "gamma"
        self.param_symbol = param_symbol    # e.g., "$\\gamma$"
        self.base_value = base_value        # Value used in baseline A1 sim
        self.filename_base = filename_base  # Base for output filenames
        self.param_values = self.df['parameter_value'].values if 'parameter_value' in self.df else None

        if self.df.empty or self.param_values is None:
             print(f"ERROR: SensitivityPlotter initialized with invalid data for {param_name}. Plotting aborted.")
             self.valid = False
        else:
             self.valid = True
             # Try to determine base index if base_value is provided
             if self.base_value is not None:
                  self.base_idx = np.argmin(np.abs(self.param_values - self.base_value))
                  # Check if the found value is close enough
                  if not np.isclose(self.param_values[self.base_idx], self.base_value):
                       print(f"Warning: Base value {self.base_value} for {self.param_name} not found exactly in range. Closest: {self.param_values[self.base_idx]}.")
                       self.base_idx = -1 # Treat as not found if not close enough
             else:
                  self.base_idx = -1 # Base value not specified


    def plot_multi_outcomes(self):
        """Plots Z_final, W_final, R_final vs the parameter value."""
        if not self.valid: return

        outcome_cols = ['Z_final', 'W_final', 'R_final']
        if not all(col in self.df.columns for col in outcome_cols):
             print(f"ERROR: Missing outcome columns for sensitivity plot {self.filename_base}.")
             return

        fig, axes = plt.subplots(3, 1, figsize=(8, 10), sharex=True)
        fig.suptitle(f"Sensitivity to {self.param_symbol} (Outcomes)", fontsize=16, y=0.98)

        colors = plt.cm.viridis(np.linspace(0.2, 0.8, 3))
        ylabels = ['Final Cumulative ICU (Z)', 'Final Cumulative Exitus (W)', 'Final Cumulative Recovered (R)']

        for i, (ax, outcome, ylabel) in enumerate(zip(axes, outcome_cols, ylabels)):
            values = self.df[outcome].values
            ax.plot(self.param_values, values, marker='o', linestyle='-', color=colors[i], markersize=6)

            # Highlight base value
            if self.base_idx != -1 and self.base_value is not None:
                 base_y = values[self.base_idx]
                 if pd.notna(base_y):
                      ax.scatter(self.base_value, base_y, color='red', s=70, zorder=5,
                                 label=f'Base {self.param_symbol}={self.base_value:.3f}' if i == 0 else "")
                      ax.axvline(self.base_value, color='grey', linestyle=':', lw=1.5)

            ax.set_ylabel(ylabel, fontsize=11)
            ax.grid(True, which='major', linestyle='-', linewidth=0.5, alpha=0.6)
            ax.tick_params(axis='y', labelsize=10)
            ax.set_ylim(bottom=0) # Ensure y-axis starts at 0
            for spine in ax.spines.values(): spine.set_visible(True) # Ensure box

            if i == 0 and self.base_idx != -1: ax.legend(fontsize=9, loc='best')
            if i == len(axes) - 1:
                ax.set_xlabel(f"Parameter Value ({self.param_symbol})", fontsize=12)
                ax.tick_params(axis='x', labelsize=10)

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        output_path = os.path.join(PLOT_OUTPUT_DIR, f"{self.filename_base}_outcomes.png")
        try:
            fig.savefig(output_path)
            print(f"Sensitivity plot saved: '{output_path}'")
        except Exception as e:
            print(f"ERROR saving sensitivity plot '{output_path}': {e}")
        plt.close(fig)


    def plot_y_peak(self):
        """Plots Y_peak vs the parameter value."""
        if not self.valid: return
        peak_col = 'Y_peak'
        if peak_col not in self.df.columns:
             print(f"ERROR: Missing '{peak_col}' column for sensitivity plot {self.filename_base}.")
             return

        fig, ax = plt.subplots(figsize=(8, 5))
        fig.suptitle(f"Sensitivity to {self.param_symbol} (Peak NIV Load)", fontsize=16, y=0.98)

        values = self.df[peak_col].values
        ax.plot(self.param_values, values, marker='o', linestyle='-', color='purple')

        # Highlight base value
        if self.base_idx != -1 and self.base_value is not None:
            base_y = values[self.base_idx]
            if pd.notna(base_y):
                ax.scatter(self.base_value, base_y, color='red', s=70, zorder=5,
                            label=f'Base {self.param_symbol}={self.base_value:.3f}')
                ax.axvline(self.base_value, color='grey', linestyle=':', lw=1.5)
                ax.legend(fontsize=9, loc='best')

        ax.set_xlabel(f"Parameter Value ({self.param_symbol})", fontsize=12)
        ax.set_ylabel("Peak NIV Patients (Y)", fontsize=12)
        ax.grid(True, which='major', linestyle='-', linewidth=0.5, alpha=0.6)
        ax.tick_params(axis='both', labelsize=10)
        ax.set_ylim(bottom=0) # Ensure y-axis starts at 0
        for spine in ax.spines.values(): spine.set_visible(True) # Ensure box

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        output_path = os.path.join(PLOT_OUTPUT_DIR, f"{self.filename_base}_Ypeak.png")
        try:
            fig.savefig(output_path)
            print(f"Sensitivity plot saved: '{output_path}'")
        except Exception as e:
            print(f"ERROR saving sensitivity plot '{output_path}': {e}")
        plt.close(fig)


# Section 8: Main Execution
# -------------------------
if __name__ == "__main__":

    print("\n--- Main Execution Start ---")

    # --- 1. Load Real Patient Data and Calculate Real Proportions ---
    real_proportions_niv = None
    try:
        # Adjust separator if needed based on actual file format
        df_real_patients = pd.read_csv(REAL_DATA_FILE, sep=',')
        metrics_real = MetricsCalculator(df_real_patients)
        real_proportions_niv = metrics_real.compute_real_cohort_proportions_for_niv()
        if real_proportions_niv is None:
             print("Warning: Could not calculate real NIV outcome proportions. Comparison text will be omitted.")
    except FileNotFoundError:
         print(f"Warning: Real patient data file '{REAL_DATA_FILE}' not found. Cannot calculate real proportions.")
    except Exception as e:
         print(f"Error loading or processing real patient data '{REAL_DATA_FILE}': {e}")


    # --- 2. Process Scenario A1 (Baseline) ---
    print("\n--- Processing Scenario A1 (Baseline) ---")
    a1_filename = SIM_FILENAMES.get("A1")
    if a1_filename:
        a1_loader = DataLoader(os.path.join(CSV_DATA_DIR, a1_filename))
        time_series_cols = ['X', 'Y', 'Z', 'W', 'R',
                            'Active_Patients_XY', 'Y_perc_vs_ActiveXY',
                            'Z_perc_vs_Cum_Admissions', 'W_perc_vs_Cum_Admissions', 'R_perc_vs_Cum_Admissions']
        a1_t, a1_series = a1_loader.get_time_series(time_series_cols)

        if a1_t is not None:
            # Calculate Metrics for A1
            a1_metrics = MetricsCalculator(a1_loader.df)
            a1_active_final, a1_perc_niv_final = a1_metrics.compute_active_niv_final()
            a1_sim_proportions = a1_metrics.compute_outcome_proportions_final()
            a1_max_y = a1_metrics.get_max_value('Y') # Store for later comparison

            # Plot Main Time Series for A1
            a1_plotter = SimulationPlotter(a1_t, a1_series, title="Figure 3A: Baseline Simulation (A1)", filename_base="Fig3A_A1_TimeSeries")
            a1_plotter.plot_main()

            # Add Text Boxes
            if pd.notna(a1_active_final) and pd.notna(a1_perc_niv_final):
                 text_a1_load = (f"Stable State:\n"
                                 f"{a1_active_final:.0f} Active Patients\n"
                                 f"{a1_perc_niv_final:.1f}% on NIV")
                 a1_plotter.add_text_box(text_a1_load, location='bottom_right') # Example location

            if real_proportions_niv is not None and not any(np.isnan(list(a1_sim_proportions.values()))):
                # Determine agreement (simple example)
                diff_z = abs(a1_sim_proportions['Z%'] - real_proportions_niv['frac_icu%'])
                agreement = "agrees well" if diff_z < 5 else "differs slightly" # Example threshold

                text_a1_comp = (f"Sim. Outcomes vs Data (NIV Cohort):\n"
                                f" ICU: {a1_sim_proportions['Z%']:.1f}% (vs {real_proportions_niv['frac_icu%']:.1f}%)\n"
                                f" Exitus: {a1_sim_proportions['W%']:.1f}% (vs {real_proportions_niv['frac_exitus%']:.1f}%)\n"
                                f" Recov.: {a1_sim_proportions['R%']:.1f}% (vs {real_proportions_niv['frac_rec%']:.1f}%)\n"
                                f" Agreement: {agreement}")
                a1_plotter.add_text_box(text_a1_comp, location='top_left') # Example location
            else:
                 # Show only simulated if real data unavailable
                 text_a1_sim_only = (f"Simulated Final Outcomes:\n"
                                     f" ICU: {a1_sim_proportions['Z%']:.1f}%\n"
                                     f" Exitus: {a1_sim_proportions['W%']:.1f}%\n"
                                     f" Recov.: {a1_sim_proportions['R%']:.1f}%")
                 a1_plotter.add_text_box(text_a1_sim_only, location='top_left')


            a1_plotter.save_plot()

            # (Optional) Plot Cumulative Rates for A1
            # a1_plotter.plot_cumulative_rates() # Uncomment to generate this plot
        else:
            print(f"Skipping A1 processing due to data loading issues.")
            a1_max_y = np.nan # Set default if A1 fails


    # --- 3. Process Scenarios B1, B2, B3 ---
    print("\n--- Processing Scenarios B1, B2, B3 ---")
    scenario_labels = {"B1": "Variable A(t)", "B2": "Variable θ(t)", "B3": "Variable A(t) & θ(t)"}
    figure_letters = {"B1": "B", "B2": "C", "B3": "D"}

    for sc_key in ["B1", "B2", "B3"]:
        print(f"--- Processing Scenario {sc_key} ---")
        sc_filename = SIM_FILENAMES.get(sc_key)
        if not sc_filename:
            print(f"Skipping {sc_key}: Filename not defined.")
            continue

        sc_loader = DataLoader(os.path.join(CSV_DATA_DIR, sc_filename))
        # Load only essential columns for the main plot + Y_peak
        sc_cols = ['X', 'Y', 'Z', 'W', 'R']
        sc_t, sc_series = sc_loader.get_time_series(sc_cols)

        if sc_t is not None:
            # Calculate Metrics for Scenario
            sc_metrics = MetricsCalculator(sc_loader.df)
            sc_sim_proportions = sc_metrics.compute_outcome_proportions_final()
            sc_max_y = sc_metrics.get_max_value('Y')

            # Plot Main Time Series
            fig_letter = figure_letters[sc_key]
            sc_plotter = SimulationPlotter(sc_t, sc_series,
                                           title=f"Figure 3{fig_letter}: {scenario_labels[sc_key]} ({sc_key})",
                                           filename_base=f"Fig3{fig_letter}_{sc_key}_TimeSeries")
            sc_plotter.plot_main() # Generate the basic plot

            # Add Peak Y Annotation and Comparison Text
            if pd.notna(sc_max_y):
                 sc_plotter.add_peak_annotation('Y', 'Peak Y')
                 if pd.notna(a1_max_y) and a1_max_y > 1e-6 :
                      peak_increase = (sc_max_y / a1_max_y - 1) * 100 if a1_max_y > 0 else float('inf')
                      peak_text = f"Peak Y: {sc_max_y:.1f}\n({peak_increase:+.1f}% vs A1 baseline)"
                 else:
                      peak_text = f"Peak Y: {sc_max_y:.1f}\n(A1 baseline Y peak N/A)"
                 sc_plotter.add_text_box(peak_text, location='bottom_right') # Modify as needed

            # Add Final Proportions Text Box
            # Comparing to A1 might be more relevant here than real data again
            if not any(np.isnan(list(sc_sim_proportions.values()))) and not any(np.isnan(list(a1_sim_proportions.values()))):
                diff_z = sc_sim_proportions['Z%'] - a1_sim_proportions['Z%']
                diff_w = sc_sim_proportions['W%'] - a1_sim_proportions['W%']
                diff_r = sc_sim_proportions['R%'] - a1_sim_proportions['R%']
                text_sc_comp = (f"Final Outcomes vs Baseline (A1):\n"
                                f" ICU: {sc_sim_proportions['Z%']:.1f}% ({diff_z:+.1f}%)\n"
                                f" Exitus: {sc_sim_proportions['W%']:.1f}% ({diff_w:+.1f}%)\n"
                                f" Recov.: {sc_sim_proportions['R%']:.1f}% ({diff_r:+.1f}%)")
                sc_plotter.add_text_box(text_sc_comp, location='top_left') # Modify as needed

            sc_plotter.save_plot()

            # Optional: Plot Cumulative Rates for Scenarios
            # sc_series_full = sc_loader.get_time_series(time_series_cols)[1] # Reload full data if needed
            # sc_plotter_full = SimulationPlotter(sc_t, sc_series_full, title=f"{sc_key} Cum Rates", filename_base=f"{sc_key}_cum_rates")
            # sc_plotter_full.plot_cumulative_rates()

        else:
            print(f"Skipping {sc_key} processing due to data loading issues.")


    # --- 4. Process Sensitivity Analyses C3, C4 (Figure 4) ---
    print("\n--- Processing Sensitivity Analyses C3 (gamma), C4 (epsilon) ---")
    sens_params = {
        "C3": {"name": "gamma", "symbol": "$\\gamma$", "base": PARAM_BASE_VALUES.get('gamma')},
        "C4": {"name": "epsilon", "symbol": "$\\epsilon$", "base": PARAM_BASE_VALUES.get('epsilon')}
    }
    figure_letters_sens = {"C3": "A,B", "C4": "C,D"} # Map C3->Fig 4A/B, C4->Fig 4C/D

    for sens_key, info in sens_params.items():
        print(f"--- Processing Sensitivity {sens_key} ({info['name']}) ---")
        sens_filename = SENS_FILENAMES.get(sens_key)
        if not sens_filename:
             print(f"Skipping {sens_key}: Filename not defined.")
             continue

        sens_loader = DataLoader(os.path.join(CSV_DATA_DIR, sens_filename))
        if sens_loader.df.empty:
             print(f"Skipping {sens_key}: Failed to load data.")
             continue

        # Try to get base value from summary file if not provided in config
        base_val_actual = info['base']
        if base_val_actual is None:
             try:
                  # Find row where parameter_value is closest to the median
                  median_param = np.median(sens_loader.df['parameter_value'])
                  base_idx = np.argmin(np.abs(sens_loader.df['parameter_value'] - median_param))
                  base_val_actual = sens_loader.df['parameter_value'].iloc[base_idx]
                  print(f"Using inferred base value for {info['name']}: {base_val_actual:.4f}")
             except:
                  print(f"Could not infer base value for {info['name']}. Plot highlighting might be absent.")


        # Instantiate Sensitivity Plotter
        plotter_sens = SensitivityPlotter(
            results_df=sens_loader.df,
            param_name=info['name'],
            param_symbol=info['symbol'],
            base_value=base_val_actual,
            filename_base=f"Fig4{figure_letters_sens[sens_key]}_{sens_key}_Sensitivity"
        )

        # Generate Plots
        plotter_sens.plot_multi_outcomes() # Fig 4A, 4C
        plotter_sens.plot_y_peak()        # Fig 4B, 4D

    print("\n--- Script Finished ---")
    #%%